{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not sure all of these are needed\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read SILVA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_id</th>\n",
       "      <th>full_taxonomy</th>\n",
       "      <th>seq_length</th>\n",
       "      <th>seq</th>\n",
       "      <th>kingdom</th>\n",
       "      <th>phylum</th>\n",
       "      <th>class</th>\n",
       "      <th>order</th>\n",
       "      <th>family</th>\n",
       "      <th>genus</th>\n",
       "      <th>species</th>\n",
       "      <th>strain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HG531388.1.1375</td>\n",
       "      <td>Bacteria;Proteobacteria;Alphaproteobacteria;Rh...</td>\n",
       "      <td>1375</td>\n",
       "      <td>AGUCGAGCGGGCGCAGCAAUGCGUCAGCGGCAGACGGGUGAGUAAC...</td>\n",
       "      <td>Bacteria</td>\n",
       "      <td>Proteobacteria</td>\n",
       "      <td>Alphaproteobacteria</td>\n",
       "      <td>Rhizobiales</td>\n",
       "      <td>Xanthobacteraceae</td>\n",
       "      <td>Rhodoplanes</td>\n",
       "      <td>Rhodoplanes oryzae</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HL281785.3.1301</td>\n",
       "      <td>Bacteria;Bacteroidota;Bacteroidia;Bacteroidale...</td>\n",
       "      <td>1299</td>\n",
       "      <td>AUUCCGGGAUAGCCUUUCGAAAGAAAGAUUAAUACUGGAUAGCAUA...</td>\n",
       "      <td>Bacteria</td>\n",
       "      <td>Bacteroidota</td>\n",
       "      <td>Bacteroidia</td>\n",
       "      <td>Bacteroidales</td>\n",
       "      <td>Bacteroidaceae</td>\n",
       "      <td>Bacteroides</td>\n",
       "      <td>unidentified</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AB002644.1.1485</td>\n",
       "      <td>Bacteria;Firmicutes;Bacilli;Bacillales;Bacilla...</td>\n",
       "      <td>1485</td>\n",
       "      <td>GGCUAAUACAUGCAAGUCGAGCGAGUGAACAAACAGAAGCCUUCGG...</td>\n",
       "      <td>Bacteria</td>\n",
       "      <td>Firmicutes</td>\n",
       "      <td>Bacilli</td>\n",
       "      <td>Bacillales</td>\n",
       "      <td>Bacillaceae</td>\n",
       "      <td>Bacillus</td>\n",
       "      <td>low G+C Gram-positive bacterium HTA454</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AB002648.1.1383</td>\n",
       "      <td>Bacteria;Firmicutes;Bacilli;Thermoactinomyceta...</td>\n",
       "      <td>1383</td>\n",
       "      <td>AGCGGCGAACGGGUGAGUAACACGNGGGUAACCUGCCCUCAAGACC...</td>\n",
       "      <td>Bacteria</td>\n",
       "      <td>Firmicutes</td>\n",
       "      <td>Bacilli</td>\n",
       "      <td>Thermoactinomycetales</td>\n",
       "      <td>Thermoactinomycetaceae</td>\n",
       "      <td>Thermoflavimicrobium</td>\n",
       "      <td>low G+C Gram-positive bacterium HTA1422</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JN049459.1.1443</td>\n",
       "      <td>Bacteria;Actinobacteriota;Actinobacteria;Strep...</td>\n",
       "      <td>1443</td>\n",
       "      <td>GACAUGGCGCCUCUACCAUGCAGUCGACGAUGACCACCUUCGGGGU...</td>\n",
       "      <td>Bacteria</td>\n",
       "      <td>Actinobacteriota</td>\n",
       "      <td>Actinobacteria</td>\n",
       "      <td>Streptomycetales</td>\n",
       "      <td>Streptomycetaceae</td>\n",
       "      <td>Streptomyces</td>\n",
       "      <td>actinobacterium ZXY010</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            raw_id                                      full_taxonomy  \\\n",
       "0  HG531388.1.1375  Bacteria;Proteobacteria;Alphaproteobacteria;Rh...   \n",
       "1  HL281785.3.1301  Bacteria;Bacteroidota;Bacteroidia;Bacteroidale...   \n",
       "2  AB002644.1.1485  Bacteria;Firmicutes;Bacilli;Bacillales;Bacilla...   \n",
       "3  AB002648.1.1383  Bacteria;Firmicutes;Bacilli;Thermoactinomyceta...   \n",
       "4  JN049459.1.1443  Bacteria;Actinobacteriota;Actinobacteria;Strep...   \n",
       "\n",
       "   seq_length                                                seq   kingdom  \\\n",
       "0        1375  AGUCGAGCGGGCGCAGCAAUGCGUCAGCGGCAGACGGGUGAGUAAC...  Bacteria   \n",
       "1        1299  AUUCCGGGAUAGCCUUUCGAAAGAAAGAUUAAUACUGGAUAGCAUA...  Bacteria   \n",
       "2        1485  GGCUAAUACAUGCAAGUCGAGCGAGUGAACAAACAGAAGCCUUCGG...  Bacteria   \n",
       "3        1383  AGCGGCGAACGGGUGAGUAACACGNGGGUAACCUGCCCUCAAGACC...  Bacteria   \n",
       "4        1443  GACAUGGCGCCUCUACCAUGCAGUCGACGAUGACCACCUUCGGGGU...  Bacteria   \n",
       "\n",
       "             phylum                class                  order  \\\n",
       "0    Proteobacteria  Alphaproteobacteria            Rhizobiales   \n",
       "1      Bacteroidota          Bacteroidia          Bacteroidales   \n",
       "2        Firmicutes              Bacilli             Bacillales   \n",
       "3        Firmicutes              Bacilli  Thermoactinomycetales   \n",
       "4  Actinobacteriota       Actinobacteria       Streptomycetales   \n",
       "\n",
       "                   family                 genus  \\\n",
       "0       Xanthobacteraceae           Rhodoplanes   \n",
       "1          Bacteroidaceae           Bacteroides   \n",
       "2             Bacillaceae              Bacillus   \n",
       "3  Thermoactinomycetaceae  Thermoflavimicrobium   \n",
       "4       Streptomycetaceae          Streptomyces   \n",
       "\n",
       "                                   species strain  \n",
       "0                       Rhodoplanes oryzae    NaN  \n",
       "1                             unidentified    NaN  \n",
       "2   low G+C Gram-positive bacterium HTA454    NaN  \n",
       "3  low G+C Gram-positive bacterium HTA1422    NaN  \n",
       "4                   actinobacterium ZXY010    NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Heavy file, takes a minute\n",
    "silva_db = pd.read_table('C:/Users/efrat/Downloads/silva_138_release/Exports/SILVA_parsed_V2.tsv', index_col = 0,\n",
    "                        dtype={'raw_id': str, \n",
    "                               \"full_taxonomy\": str, \n",
    "                               \"seq_length\": int,\n",
    "                               \"seq\": str, \n",
    "                               \"kingdom\": str, \n",
    "                               \"phylum\": str, \n",
    "                               \"class\": str, \n",
    "                               \"order\": str, \n",
    "                               \"family\": str,\n",
    "                               \"genus\": str,\n",
    "                               \"species\": str,\n",
    "                               \"strain\": str})\n",
    "silva_db.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "432033 sequences total in db\n"
     ]
    }
   ],
   "source": [
    "# Create list of all sequences in our data and convert to lowercase\n",
    "seqs = silva_db.seq.values\n",
    "seqs = [s.lower() for s in seqs]\n",
    "#seqs[0:2]\n",
    "print(len(seqs),\"sequences total in db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read BPE tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the BPE tokenizer\n",
    "vocab = \"C:/Users/efrat/Documents/DNA_BERT_Data/tokens/vocab_15K/vocab.json\"\n",
    "merges = \"C:/Users/efrat/Documents/DNA_BERT_Data/tokens/vocab_15K/merges.txt\"\n",
    "tokenizer_15K = Tokenizer(BPE())\n",
    "tokenizer_15K.model = BPE(vocab, merges)\n",
    "vocab_dict = json.load(open(vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get k-mer tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "# Given a sequence and k-length, return the unique set of k-mers\n",
    "def get_kmers_seq(seq, k):\n",
    "    # Start with an empty set\n",
    "    kmers = set()\n",
    "    # Calculate how many kmers of length k there are\n",
    "    num_kmers = len(seq) - k + 1\n",
    "    # Loop over the kmer start positions\n",
    "    for i in range(num_kmers):\n",
    "        # Slice the string to get the kmer\n",
    "        kmer = seq[i:i+k]\n",
    "        # Add the kmer to the dictionary if it's not there\n",
    "        kmers.add(kmer)\n",
    "    # Return the final counts\n",
    "    return kmers\n",
    "\n",
    "def get_kmers(seqs, k):\n",
    "    kmers = set()\n",
    "    n = len(seqs)\n",
    "    i = 0\n",
    "    for seq in seqs:\n",
    "        i += 1\n",
    "        if i%1000 == 0:\n",
    "            print(\".\", end=' ')\n",
    "        kmers = kmers.union(get_kmers_seq(seq, k))\n",
    "    return kmers\n",
    "    \n",
    "def encode_kmers(seq, k):\n",
    "    kmer_encoding = []\n",
    "    num_kmers = len(seq) - k + 1\n",
    "    for i in range(num_kmers):\n",
    "        kmer = seq[i:i+k]\n",
    "        kmer_encoding.append(kmer)\n",
    "    return kmer_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we calculate the actual vocab' size per k = 8/10/12\n",
    "#kmer_vocab_8 = get_kmers(seqs, 8)\n",
    "#print(\"8-mer vocab size:\", len(kmer_vocab_8)) # --> 259339\n",
    "#kmer_vocab_10 = get_kmers(seqs, 10)\n",
    "#print(\"10-mer vocab size:\", len(kmer_vocab_10)) # --> 1611004\n",
    "#kmer_vocab_6 = get_kmers(seqs, 6)\n",
    "#print(\"6-mer vocab size:\", len(kmer_vocab_6)) # --> 15621\n",
    "#kmer_vocab_4 = get_kmers(seqs, 4)\n",
    "#print(\"4-mer vocab size:\", len(kmer_vocab_4)) # --> 625"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a matrix of tokens-in-sequences\n",
    "The matrix (all_encodings_cv) will be sparse. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Example - encoding with our tokens\n",
    "encoding = tokenizer_2K.encode(\"AGACACGGCCCAGACUCCUACGGGAGGCAGCAGUGGGGAAUAUUGGACAAUGGGGGCAACCCUGAUCCAGCCAUGCCGCGUGAGUGAUGAAGGCCCUAGGGUUGUAAAGCUCUUUCGGUGGGGAAGAUAAUGACGGUACCCACAGAAGAAGCCCCGGCUAACUUCGUGCCAGCAGCCGCGGUAAUACGAAGGGGGCUAGCGUUGCUCGGAAUCACUGGGCGUAAAGCGCACGUAGGCGGCUUUCUAAGUCAGGGGUGAAAUCCCGGAGCUCAACUCCGGAACUGCCUUUGAUACUGGGAGGCUCGAGUCCGGGAGAGGUGAGUGGAACUGCGAGUGUAGAGGUGAAAUUCGUAGAUAUUCGCAAGAACACCAGUGGCGAAGGCGGCUCACUGGCCCGGUACUGACGCUGAGGUGCGAAAGCGUGGGGAGCAAACAGGAUUAGAUACCCUGGUAGUCCACGCCGUAAACGAUGGAUGCUAGCCGUUGGGCAGCUUGCUGCUCAGUGGCGCAGCUAACGCCUUAAGCAUCCCGCCUGGGGAGUACGGUCGCAAGAUUAAAACUCAAAGGAAUUGACGGGGGCCCGCACAAGCGGUGGAGCAUGUGGUUUAAUUUCGAAGCAACGCGCAGAACCUUACCAGCUCUUGACAUGCCACGACGGUUUCCGGAGACGGACUCCACCCCGCAAGGGGCGUGGACACAGGUGCCUGCAUGGCUGUCGUCAGCUCGUGUCGUGAGAUGUUGGGUUAAGUCC\".lower())\n",
    "print(\"Encoded string:\\n{}\".format(encoding.tokens))\n",
    "print()\n",
    "print(\"Encoded string - in token IDs:\\n{}\".format(encoding.ids))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Sequences - example of batch encoding\n",
    "seqs = ['ACACGGCCCAGACUCCUACGGGAGGCAGCAGUGGGGAAUAUUGGACAAUGGGGGCAACCCUGAUCCAGCCAUG', 'GUGGGGAAGAUAAUGACGGUACC', 'GCCGCGGUAAUACGAAGGGGGCUAGCGUUGCUCGGAAUCACUGGGCGUAAAGCGCACGUAGGCGGCUUUCUAAGUCAGGGGU']\n",
    "seqs = [s.lower() for s in seqs]\n",
    "all_encodings = [tokenizer_2K.encode(s).tokens for s in seqs]\n",
    "all_encodings[0][0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-07-19 10:04:55.990637\n",
      "(432033, 15620)\n",
      "2020-07-19 10:13:36.145018\n"
     ]
    }
   ],
   "source": [
    "# Use sklearn to batch encode all sequences and convert to a matrix (takes a few minutes)\n",
    "print(datetime.datetime.now())\n",
    "cv = CountVectorizer(tokenizer = lambda x: tokenizer_15K.encode(x).tokens, lowercase = True)\n",
    "all_encodings_cv_bpe = cv.fit_transform(seqs)\n",
    "token_strings_bpe = cv.get_feature_names()\n",
    "print(all_encodings_cv_bpe.shape)\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same for kmer-based tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-07-19 10:13:36.152964\n",
      "(432033, 15621)\n",
      "2020-07-19 10:20:11.005341\n"
     ]
    }
   ],
   "source": [
    "print(datetime.datetime.now())\n",
    "cv_6mer = CountVectorizer(tokenizer = lambda x: encode_kmers(x, 6), lowercase = True)\n",
    "all_encodings_cv_6mer = cv_6mer.fit_transform(seqs)\n",
    "token_strings_6mer = cv_6mer.get_feature_names()\n",
    "print(all_encodings_cv_6mer.shape)\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokens analysis\n",
    "\n",
    "Per token, we collect the following statistics:\n",
    "* token + token id (identifiers)\n",
    "* token_length\n",
    "* total_num_of_appearances\n",
    "\n",
    "And for each taxonomic level ('phylum','class','order','family','genus','species','strain'):\n",
    "* token_id\n",
    "* tax_level \n",
    "* tax_name\n",
    "* num_appearances\n",
    "\n",
    "These will help us understand which tokens are widely shared (and not short, so not trivial) and which are clade specific.\n",
    "\n",
    "### Collect statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each token, get its total count of appearances (a token may appear multiple times in a single sequence)\n",
    "def get_token_appearances(encodings_cv):\n",
    "    token_appearances = encodings_cv.sum(0).tolist()\n",
    "    token_appearances = [i for sublist in token_appearances for i in sublist]\n",
    "    return token_appearances\n",
    "\n",
    "# For each token, get the number of unique sequences it appears in \n",
    "def get_token_appearances_uniq(encodings_cv):\n",
    "    token_appearances_uniq = (encodings_cv != 0).sum(0).tolist()\n",
    "    token_appearances_uniq = [i for sublist in token_appearances_uniq for i in sublist]\n",
    "    return token_appearances_uniq\n",
    "\n",
    "# For each token, collect clade-specific stats\n",
    "# (Currently takes several minutes)\n",
    "def get_clade_spec_stats(encodings_cv, column_names, calc_stats_flags, silva_db):\n",
    "    nseqs = encodings_cv.shape[0]\n",
    "    # Init' empty dataset\n",
    "    token_taxon_stats = pd.DataFrame(columns=['token','tax_level','tax_name','n_occurrences']) \n",
    "\n",
    "    # Iterate over tokens, only if flag calc_stats_flags = True\n",
    "    for i in range(0, len(column_names)):\n",
    "        if i%100 == 0: print('.', end = '')\n",
    "        if i%5000 == 0: print(\"Completed\",i,\"/\",len(column_names),\"tokens\")\n",
    "        if not calc_stats_flags[i]: continue\n",
    "        current_token = column_names[i]\n",
    "        seq_appearances_vec = encodings_cv.getcol(i)\n",
    "        seq_appearances_vec = [j[0] for j in seq_appearances_vec.toarray()] # flatten\n",
    "        # Get indices of relevant sequences\n",
    "        seqs_ids = [j for j, val in enumerate(seq_appearances_vec) if val == 1] \n",
    "        # Get metadata rows for the sequences in above indices\n",
    "        db_subset = silva_db.loc[seqs_ids, ]\n",
    "\n",
    "        # Iterate over taxonomic levels to get level-specific stats\n",
    "        for tax_level in ['phylum','class','order','family','genus','species','strain']:\n",
    "            level_counts = db_subset.groupby(tax_level, as_index = False).agg({'raw_id':'count'})\n",
    "            level_counts = level_counts[level_counts['raw_id'] > 4] # We remove entities with only few hits, to reduce noise\n",
    "            level_counts.columns = ['tax_name', 'n_occurrences']\n",
    "            level_counts['tax_level'] = tax_level\n",
    "            level_counts['token'] = current_token\n",
    "            #print(level_counts.head())\n",
    "            token_taxon_stats = token_taxon_stats.append(level_counts)\n",
    "\n",
    "    return token_taxon_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15620\n",
      "15620\n"
     ]
    }
   ],
   "source": [
    "# Analyze bpe tokens (appearances stats)\n",
    "bpe_token_appearances = get_token_appearances(all_encodings_cv_bpe)\n",
    "# Sanity (should be same size as vocab size)\n",
    "print(len(bpe_token_appearances))\n",
    "\n",
    "bpe_token_appearances_uniq = get_token_appearances_uniq(all_encodings_cv_bpe)\n",
    "# Sanity (should be same size as vocab size)\n",
    "print(len(bpe_token_appearances_uniq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15621\n",
      "15621\n"
     ]
    }
   ],
   "source": [
    "# Analyze k-mer tokens (appearances stats)\n",
    "kmer_token_appearances = get_token_appearances(all_encodings_cv_6mer)\n",
    "# Sanity (should be same size as vocab size)\n",
    "print(len(kmer_token_appearances))\n",
    "\n",
    "kmer_token_appearances_uniq = get_token_appearances_uniq(all_encodings_cv_6mer)\n",
    "# Sanity (should be same size as vocab size)\n",
    "print(len(kmer_token_appearances_uniq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token_length</th>\n",
       "      <th>total_appearances_mult_in_seq</th>\n",
       "      <th>total_seqs_in</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20740</td>\n",
       "      <td>20626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aa</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>82693</td>\n",
       "      <td>72322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aaaa</td>\n",
       "      <td>326</td>\n",
       "      <td>4</td>\n",
       "      <td>49389</td>\n",
       "      <td>42937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aaaaac</td>\n",
       "      <td>4433</td>\n",
       "      <td>6</td>\n",
       "      <td>4242</td>\n",
       "      <td>4165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aaaaagc</td>\n",
       "      <td>4996</td>\n",
       "      <td>7</td>\n",
       "      <td>2373</td>\n",
       "      <td>2371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>aaaaagg</td>\n",
       "      <td>9724</td>\n",
       "      <td>7</td>\n",
       "      <td>1528</td>\n",
       "      <td>1517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>aaaaagu</td>\n",
       "      <td>11317</td>\n",
       "      <td>7</td>\n",
       "      <td>1253</td>\n",
       "      <td>1222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>aaaaau</td>\n",
       "      <td>6347</td>\n",
       "      <td>6</td>\n",
       "      <td>2642</td>\n",
       "      <td>2635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>aaaaaugacgguac</td>\n",
       "      <td>8190</td>\n",
       "      <td>14</td>\n",
       "      <td>1899</td>\n",
       "      <td>1899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>aaaacagg</td>\n",
       "      <td>8369</td>\n",
       "      <td>8</td>\n",
       "      <td>1846</td>\n",
       "      <td>1843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            token  token_id  token_length  total_appearances_mult_in_seq  \\\n",
       "0               a         0             1                          20740   \n",
       "1              aa         6             2                          82693   \n",
       "2            aaaa       326             4                          49389   \n",
       "3          aaaaac      4433             6                           4242   \n",
       "4         aaaaagc      4996             7                           2373   \n",
       "5         aaaaagg      9724             7                           1528   \n",
       "6         aaaaagu     11317             7                           1253   \n",
       "7          aaaaau      6347             6                           2642   \n",
       "8  aaaaaugacgguac      8190            14                           1899   \n",
       "9        aaaacagg      8369             8                           1846   \n",
       "\n",
       "   total_seqs_in  \n",
       "0          20626  \n",
       "1          72322  \n",
       "2          42937  \n",
       "3           4165  \n",
       "4           2371  \n",
       "5           1517  \n",
       "6           1222  \n",
       "7           2635  \n",
       "8           1899  \n",
       "9           1843  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Organize stats into a single data frame - BPE\n",
    "token_ids = [vocab_dict[t] for t in token_strings_bpe]\n",
    "token_lengths = [len(t) for t in token_strings_bpe]\n",
    "token_stats_bpe = pd.DataFrame(list(zip(token_strings_bpe, \n",
    "                                    token_ids,\n",
    "                                    token_lengths, \n",
    "                                    bpe_token_appearances, \n",
    "                                    bpe_token_appearances_uniq)), \n",
    "                           columns =['token', 'token_id', 'token_length', 'total_appearances_mult_in_seq', 'total_seqs_in']) \n",
    "token_stats_bpe.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>total_appearances_mult_in_seq</th>\n",
       "      <th>total_seqs_in</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aaaaaa</td>\n",
       "      <td>52262</td>\n",
       "      <td>38457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aaaaac</td>\n",
       "      <td>95941</td>\n",
       "      <td>89694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aaaaag</td>\n",
       "      <td>107978</td>\n",
       "      <td>97615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aaaaan</td>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aaaaau</td>\n",
       "      <td>41319</td>\n",
       "      <td>38144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>aaaaca</td>\n",
       "      <td>29827</td>\n",
       "      <td>27517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>aaaacc</td>\n",
       "      <td>152322</td>\n",
       "      <td>130079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>aaaacg</td>\n",
       "      <td>45603</td>\n",
       "      <td>39375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>aaaacn</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>aaaacu</td>\n",
       "      <td>358216</td>\n",
       "      <td>289497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    token  total_appearances_mult_in_seq  total_seqs_in\n",
       "0  aaaaaa                          52262          38457\n",
       "1  aaaaac                          95941          89694\n",
       "2  aaaaag                         107978          97615\n",
       "3  aaaaan                             91             91\n",
       "4  aaaaau                          41319          38144\n",
       "5  aaaaca                          29827          27517\n",
       "6  aaaacc                         152322         130079\n",
       "7  aaaacg                          45603          39375\n",
       "8  aaaacn                             75             75\n",
       "9  aaaacu                         358216         289497"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Same for k-mer\n",
    "token_stats_6mer = pd.DataFrame(list(zip(token_strings_6mer, kmer_token_appearances, kmer_token_appearances_uniq)), \n",
    "                           columns =['token', 'total_appearances_mult_in_seq', 'total_seqs_in']) \n",
    "token_stats_6mer.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the BPE vocab, clade-specificity stats will be collected for 15603 tokens instead of 15620\n",
      "For the k-mer vocab, clade-specificity stats will be collected for 14325 tokens instead of 15621\n"
     ]
    }
   ],
   "source": [
    "# We next want to collect stats about whether each token is clade-specific or not. \n",
    "# Optionally, to reduce runtime / focus on main tokens, we can calculate this for tokens with > 10 apearences only\n",
    "print(\"For the BPE vocab, clade-specificity stats will be collected for\",\n",
    "      len(token_stats_bpe[token_stats_bpe.total_seqs_in >= 10]),\n",
    "      \"tokens instead of\",len(token_stats_bpe))\n",
    "print(\"For the k-mer vocab, clade-specificity stats will be collected for\",\n",
    "      len(token_stats_6mer[token_stats_6mer.total_seqs_in >= 10]),\n",
    "      \"tokens instead of\",len(token_stats_6mer))\n",
    "\n",
    "include_token_bpe = list(token_stats_bpe.total_seqs_in >= 10)\n",
    "include_token_6mer = list(token_stats_6mer.total_seqs_in >= 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".Completed 0 / 15620 tokens\n",
      "....................................................................................................Completed 10000 / 15620 tokens\n",
      "........................................................"
     ]
    }
   ],
   "source": [
    "# For each token, collect clade-specific stats\n",
    "token_taxon_stats_bpe = get_clade_spec_stats(all_encodings_cv_bpe, token_strings_bpe, include_token_bpe, silva_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".Completed 0 / 15621 tokens\n",
      "..................................................Completed 5000 / 15621 tokens\n",
      "..................................................Completed 10000 / 15621 tokens\n",
      "..........................................."
     ]
    }
   ],
   "source": [
    "token_taxon_stats_6mer = get_clade_spec_stats(all_encodings_cv_6mer, token_strings_6mer, include_token_6mer, silva_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15620, 4)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_stats_6mer.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Just for testing - NO RUN\n",
    "token_taxon_stats = pd.DataFrame(columns=['token','tax_level','tax_name','n_occurrences']) # Init' empty dataset\n",
    "i=8\n",
    "\n",
    "current_token = column_names[i]\n",
    "print(current_token)\n",
    "seq_appearances_vec = all_encodings_cv.getcol(i)\n",
    "print(seq_appearances_vec.shape)\n",
    "seq_appearances_vec = [j[0] for j in seq_appearances_vec.toarray()] # flatten\n",
    "print(len(seq_appearances_vec))\n",
    "seqs_ids = [j for j, val in enumerate(seq_appearances_vec) if val == 1] \n",
    "print(seqs_ids[0:10])\n",
    "db_subset = silva_db.loc[seqs_ids, ]\n",
    "#print(db_subset.head(10))\n",
    "\n",
    "# Iterate over taxonomic levels to get level-specific stats\n",
    "for tax_level in ['phylum','class','order','family','genus','species','strain']:\n",
    "    level_counts = db_subset.groupby(tax_level, as_index = False).agg({'raw_id':'count'})\n",
    "    level_counts = level_counts[level_counts['raw_id']>2]\n",
    "    level_counts.columns = ['tax_name', 'n_occurrences']\n",
    "    level_counts['tax_level'] = tax_level\n",
    "    level_counts['token'] = current_token\n",
    "    #print(level_counts.head())\n",
    "    token_taxon_stats = token_taxon_stats.append(level_counts)\n",
    "\n",
    "token_taxon_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to file\n",
    "token_taxon_stats_bpe.to_csv(path_or_buf = \"C:/Users/efrat/Documents/DNA_BERT_Data/tokens/tokens_15K_tax_level_specific_stats.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_taxon_stats_6mer.to_csv(path_or_buf = \"C:/Users/efrat/Documents/DNA_BERT_Data/tokens/tokens_6mers_tax_level_specific_stats.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To label tokens as clade-specific, we apply the following logic, per taxonomic level (e.g. phyla):\n",
    "- for each clade (e.g. each phylum) we count the number of sequences in that clade in which the token appeared (once or more)\n",
    "- if more than 99% of the sequences containing the token belong to a single clade, we call the taxon clade-specific (we allow 3% for other clades to account for the noisy nature of the data, and the expected annotation mistakes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summarized_token_taxon_stats(token_stats, token_taxon_stats):\n",
    "    # We'll take the max count per clade\n",
    "    token_taxon_sum = token_taxon_stats.groupby(['token', 'tax_level'], as_index = False).agg({'n_occurrences':'max'})\n",
    "    token_taxon_sum.columns = ['token', 'tax_level', 'max_occurrences_specific_clade']\n",
    "\n",
    "    # Re-organize the table\n",
    "    token_taxon_sum = token_taxon_sum.pivot_table(index=['token'], \n",
    "                                                  columns='tax_level', \n",
    "                                                  values='max_occurrences_specific_clade').reset_index()\n",
    "    token_taxon_sum.columns = [c if c==\"token\" else \"max_in_single_\"+c for c in token_taxon_sum.columns]\n",
    "\n",
    "    # Merge with the other stats\n",
    "    token_stats2 = pd.merge(token_stats, token_taxon_sum, on='token')\n",
    "\n",
    "    # And now we compute the max % of appearances in a single clade\n",
    "    token_stats2['max_perc_in_single_class'] = token_stats2['max_in_single_class'] * 100.0 / token_stats2['total_seqs_in']\n",
    "    token_stats2['max_perc_in_single_family'] = token_stats2['max_in_single_family'] * 100.0 / token_stats2['total_seqs_in']\n",
    "    token_stats2['max_perc_in_single_genus'] = token_stats2['max_in_single_genus'] * 100.0 / token_stats2['total_seqs_in']\n",
    "    token_stats2['max_perc_in_single_species'] = token_stats2['max_in_single_species'] * 100.0 / token_stats2['total_seqs_in']\n",
    "    token_stats2['max_perc_in_single_phylum'] = token_stats2['max_in_single_phylum'] * 100.0 / token_stats2['total_seqs_in']\n",
    "    token_stats2['max_perc_in_single_order'] = token_stats2['max_in_single_order'] * 100.0 / token_stats2['total_seqs_in']\n",
    "    token_stats2['max_perc_in_single_strain'] = token_stats2['max_in_single_strain'] * 100.0 / token_stats2['total_seqs_in']\n",
    "\n",
    "    # And label each token as clade-specific or not...\n",
    "    token_stats2['clade_specific_class'] = token_stats2['max_perc_in_single_class'] > 99\n",
    "    token_stats2['clade_specific_family'] = token_stats2['max_perc_in_single_family'] > 99\n",
    "    token_stats2['clade_specific_genus'] = token_stats2['max_perc_in_single_genus'] > 99\n",
    "    token_stats2['clade_specific_species'] = token_stats2['max_perc_in_single_species'] > 99\n",
    "    token_stats2['clade_specific_phylum'] = token_stats2['max_perc_in_single_phylum'] > 99\n",
    "    token_stats2['clade_specific_order'] = token_stats2['max_perc_in_single_order'] > 99\n",
    "    token_stats2['clade_specific_strain'] = token_stats2['max_perc_in_single_strain'] > 99\n",
    "\n",
    "    token_stats2['clade_specific_any'] = (token_stats2['clade_specific_strain'] | \n",
    "                token_stats2['clade_specific_species'] |\n",
    "                token_stats2['clade_specific_genus'] |\n",
    "                token_stats2['clade_specific_family'] |\n",
    "                token_stats2['clade_specific_order'] |\n",
    "                token_stats2['clade_specific_class'] |\n",
    "                token_stats2['clade_specific_phylum'])\n",
    "\n",
    "    # One additional statistic\n",
    "    token_stats2['avg_occur_in_seq'] = token_stats2['total_appearances_mult_in_seq'] / token_stats2['total_seqs_in']\n",
    "    \n",
    "    return(token_stats2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token_length</th>\n",
       "      <th>total_appearances_mult_in_seq</th>\n",
       "      <th>total_seqs_in</th>\n",
       "      <th>max_in_single_class</th>\n",
       "      <th>max_in_single_family</th>\n",
       "      <th>max_in_single_genus</th>\n",
       "      <th>max_in_single_order</th>\n",
       "      <th>max_in_single_phylum</th>\n",
       "      <th>...</th>\n",
       "      <th>max_perc_in_single_strain</th>\n",
       "      <th>clade_specific_class</th>\n",
       "      <th>clade_specific_family</th>\n",
       "      <th>clade_specific_genus</th>\n",
       "      <th>clade_specific_species</th>\n",
       "      <th>clade_specific_phylum</th>\n",
       "      <th>clade_specific_order</th>\n",
       "      <th>clade_specific_strain</th>\n",
       "      <th>clade_specific_any</th>\n",
       "      <th>avg_occur_in_seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20740</td>\n",
       "      <td>20626</td>\n",
       "      <td>3741.0</td>\n",
       "      <td>1399.0</td>\n",
       "      <td>1554.0</td>\n",
       "      <td>1524.0</td>\n",
       "      <td>6348.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.005527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aa</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>82693</td>\n",
       "      <td>72322</td>\n",
       "      <td>9796.0</td>\n",
       "      <td>3390.0</td>\n",
       "      <td>4973.0</td>\n",
       "      <td>3358.0</td>\n",
       "      <td>18807.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.143400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aaaa</td>\n",
       "      <td>326</td>\n",
       "      <td>4</td>\n",
       "      <td>49389</td>\n",
       "      <td>42937</td>\n",
       "      <td>6057.0</td>\n",
       "      <td>2134.0</td>\n",
       "      <td>3164.0</td>\n",
       "      <td>2415.0</td>\n",
       "      <td>13196.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.150267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aaaaac</td>\n",
       "      <td>4433</td>\n",
       "      <td>6</td>\n",
       "      <td>4242</td>\n",
       "      <td>4165</td>\n",
       "      <td>1319.0</td>\n",
       "      <td>465.0</td>\n",
       "      <td>305.0</td>\n",
       "      <td>468.0</td>\n",
       "      <td>2370.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.018487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aaaaagc</td>\n",
       "      <td>4996</td>\n",
       "      <td>7</td>\n",
       "      <td>2373</td>\n",
       "      <td>2371</td>\n",
       "      <td>404.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>918.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     token  token_id  token_length  total_appearances_mult_in_seq  \\\n",
       "0        a         0             1                          20740   \n",
       "1       aa         6             2                          82693   \n",
       "2     aaaa       326             4                          49389   \n",
       "3   aaaaac      4433             6                           4242   \n",
       "4  aaaaagc      4996             7                           2373   \n",
       "\n",
       "   total_seqs_in  max_in_single_class  max_in_single_family  \\\n",
       "0          20626               3741.0                1399.0   \n",
       "1          72322               9796.0                3390.0   \n",
       "2          42937               6057.0                2134.0   \n",
       "3           4165               1319.0                 465.0   \n",
       "4           2371                404.0                 188.0   \n",
       "\n",
       "   max_in_single_genus  max_in_single_order  max_in_single_phylum  ...  \\\n",
       "0               1554.0               1524.0                6348.0  ...   \n",
       "1               4973.0               3358.0               18807.0  ...   \n",
       "2               3164.0               2415.0               13196.0  ...   \n",
       "3                305.0                468.0                2370.0  ...   \n",
       "4                218.0                205.0                 918.0  ...   \n",
       "\n",
       "   max_perc_in_single_strain  clade_specific_class  clade_specific_family  \\\n",
       "0                        NaN                 False                  False   \n",
       "1                        NaN                 False                  False   \n",
       "2                        NaN                 False                  False   \n",
       "3                        NaN                 False                  False   \n",
       "4                        NaN                 False                  False   \n",
       "\n",
       "   clade_specific_genus  clade_specific_species  clade_specific_phylum  \\\n",
       "0                 False                   False                  False   \n",
       "1                 False                   False                  False   \n",
       "2                 False                   False                  False   \n",
       "3                 False                   False                  False   \n",
       "4                 False                   False                  False   \n",
       "\n",
       "   clade_specific_order  clade_specific_strain  clade_specific_any  \\\n",
       "0                 False                  False               False   \n",
       "1                 False                  False               False   \n",
       "2                 False                  False               False   \n",
       "3                 False                  False               False   \n",
       "4                 False                  False               False   \n",
       "\n",
       "   avg_occur_in_seq  \n",
       "0          1.005527  \n",
       "1          1.143400  \n",
       "2          1.150267  \n",
       "3          1.018487  \n",
       "4          1.000844  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summarize - BPE stats \n",
    "token_stats_bpe2 = get_summarized_token_taxon_stats(token_stats_bpe, token_taxon_stats_bpe)\n",
    "\n",
    "# Save\n",
    "token_stats_bpe2.to_csv(path_or_buf = \"C:/Users/efrat/Documents/DNA_BERT_Data/tokens/tokens_15K_tax_level_summarized_stats.tsv\", sep='\\t')\n",
    "token_stats_bpe2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_stats_bpe2[token_stats_bpe2['clade_specific_any']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same for 8-mers (TODO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze\n",
    "\n",
    "(1) Token length vs. number of sequences appearing in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,5))\n",
    "plt.rc('font', size=12)\n",
    "plt.scatter(x = token_stats2['total_seqs_in'], \n",
    "            y = token_stats2['token_length'], \n",
    "            c = token_stats2['avg_occur_in_seq'], \n",
    "            alpha = 0.2,\n",
    "            cmap = 'viridis')\n",
    "plt.colorbar(label='Average occurrences per sequence')\n",
    "plt.xlabel('Total sequences token is contained in')\n",
    "plt.ylabel('Token length')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) numbers of clade-specific tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.melt(token_stats2, id_vars=['token'], \n",
    "              value_vars=['max_perc_in_single_class', 'max_perc_in_single_family', \n",
    "                          'max_perc_in_single_genus', 'max_perc_in_single_species',\n",
    "                          'max_perc_in_single_phylum', 'max_perc_in_single_order',\n",
    "                          'max_perc_in_single_strain'])\n",
    "tmp['variable2'] = tmp['variable'].replace({'max_perc_in_single_':'Number of clade-specific tokens: '}, regex=True)\n",
    "tmp = tmp[tmp['value'] > 97]\n",
    "tmp.groupby('variable2', as_index = False)['value'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(1, figsize=(6, 5))\n",
    "ax = fig.add_subplot(111)\n",
    "bp = ax.boxplot([token_stats2.loc[token_stats2['clade_specific_any'], ]['token_length'],\n",
    "                 token_stats2.loc[~token_stats2['clade_specific_any'], ]['token_length']], patch_artist=True)\n",
    "ax.set_xticklabels(['Clade specific tokens', 'Other tokens'])\n",
    "ax.set_ylabel('Token length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
