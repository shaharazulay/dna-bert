{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bert Masked Training.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a9c2a1846e7e43648124311181fb771a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3d17a08352114cbfb0bfb479f2e601c5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e056886b21c44b0798a44c87464f16b2",
              "IPY_MODEL_ad0ba16983b645719ca351a06065e1a0"
            ]
          }
        },
        "3d17a08352114cbfb0bfb479f2e601c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e056886b21c44b0798a44c87464f16b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_660d63e998754b43b9c7492ff42f0e06",
            "_dom_classes": [],
            "description": "Epoch:   0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 3,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7139c90a9aa14f67a27c1a0ec3a1d7c8"
          }
        },
        "ad0ba16983b645719ca351a06065e1a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fcb338f7c24f4c7a8a267386076370d8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/3 [2:43:10&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_44ad9ecd2cea45249cca13ed2956ce18"
          }
        },
        "660d63e998754b43b9c7492ff42f0e06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7139c90a9aa14f67a27c1a0ec3a1d7c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fcb338f7c24f4c7a8a267386076370d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "44ad9ecd2cea45249cca13ed2956ce18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d5a0e91565af4310bdc670c24cc23b32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_febc1871ad444bcca80f08f6bfbcc638",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5dd1fc6a76514087901ac891f1c81898",
              "IPY_MODEL_70fd567916ef4c85bdf4ff31451e2c90"
            ]
          }
        },
        "febc1871ad444bcca80f08f6bfbcc638": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5dd1fc6a76514087901ac891f1c81898": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_62612890d16749bdb745291bab447bdf",
            "_dom_classes": [],
            "description": "Iteration:  93%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 10801,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 9999,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6c21a75b5b0847c5a02332e4eb81dc77"
          }
        },
        "70fd567916ef4c85bdf4ff31451e2c90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4652f026b93f4a33bcfc8e63e6c560c4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 9999/10801 [2:43:10&lt;13:07,  1.02it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5727a783b17b4839be3e9418f268f773"
          }
        },
        "62612890d16749bdb745291bab447bdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6c21a75b5b0847c5a02332e4eb81dc77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4652f026b93f4a33bcfc8e63e6c560c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5727a783b17b4839be3e9418f268f773": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbu3icXhyiTI",
        "colab_type": "text"
      },
      "source": [
        "Installs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_iyEf3wyxrj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "ede9707d-7a5f-43a8-f411-a445007e3305"
      },
      "source": [
        "pip install tokenizers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tokenizers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e9/ee/fedc3509145ad60fe5b418783f4a4c1b5462a4f0e8c7bbdbda52bdcda486/tokenizers-0.8.1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 9.0MB/s \n",
            "\u001b[?25hInstalling collected packages: tokenizers\n",
            "Successfully installed tokenizers-0.8.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IadLzj6xrps",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        },
        "outputId": "b374aa87-12b1-4cd5-a631-aa6750e9e241"
      },
      "source": [
        "pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
            "\r\u001b[K     |▍                               | 10kB 16.6MB/s eta 0:00:01\r\u001b[K     |▉                               | 20kB 6.1MB/s eta 0:00:01\r\u001b[K     |█▎                              | 30kB 7.1MB/s eta 0:00:01\r\u001b[K     |█▊                              | 40kB 8.0MB/s eta 0:00:01\r\u001b[K     |██▏                             | 51kB 6.4MB/s eta 0:00:01\r\u001b[K     |██▋                             | 61kB 6.9MB/s eta 0:00:01\r\u001b[K     |███                             | 71kB 7.3MB/s eta 0:00:01\r\u001b[K     |███▍                            | 81kB 8.0MB/s eta 0:00:01\r\u001b[K     |███▉                            | 92kB 8.3MB/s eta 0:00:01\r\u001b[K     |████▎                           | 102kB 8.7MB/s eta 0:00:01\r\u001b[K     |████▊                           | 112kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 122kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 133kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████                          | 143kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 153kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 163kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 174kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 184kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████                        | 194kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 204kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████                       | 215kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 225kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 235kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 245kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 256kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████                     | 266kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 276kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████                    | 286kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 296kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 307kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 317kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 327kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 337kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 348kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 358kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 368kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 378kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 389kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 399kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 409kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 419kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 430kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 440kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 450kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 460kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 471kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 481kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 491kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 501kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 512kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 522kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 532kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 542kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 552kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 563kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 573kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 583kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 593kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 604kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 614kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 624kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 634kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 645kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 655kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 665kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 675kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 686kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 696kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 706kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 716kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 727kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 737kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 747kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 757kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 768kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 778kB 8.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 28.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 39.8MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.8.1.rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 46.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=1ca378681e5aa785fdf5c9a1596a394312531080049c9237fd4cf8e7dc33de4b\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, sentencepiece, tokenizers, transformers\n",
            "  Found existing installation: tokenizers 0.8.1\n",
            "    Uninstalling tokenizers-0.8.1:\n",
            "      Successfully uninstalled tokenizers-0.8.1\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoKoiyUEylkJ",
        "colab_type": "text"
      },
      "source": [
        "Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TthZlyyJyY3T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from transformers import BertConfig, BertForMaskedLM, BertModel\n",
        "from transformers import Trainer, TrainingArguments\n",
        "from tokenizers import BertWordPieceTokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JLZZrO1lKy_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from _dataset import BERT16SDataset\n",
        "from _collator import DataCollatorForBertWordPieceTokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkAMgNxK4khv",
        "colab_type": "text"
      },
      "source": [
        "Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-J1ZQJuPZKst",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "4a76f767-f837-4ba0-a3f2-a1971d637055"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upDeEcu58OV2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "drive_path = './drive/My Drive/Colab Notebooks/NLP/model'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvHYuIuj1BcM",
        "colab_type": "text"
      },
      "source": [
        "Check Resources"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3Xj2H8S0uNV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6c2c46a0-1683-4299-ef94-7fb1af2c4ee4"
      },
      "source": [
        "# Check that we have a GPU\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAyNR0iZ1EZf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ec86fb64-2b5b-4a15-ea26-39fe55d5617c"
      },
      "source": [
        "# Check that PyTorch sees it\n",
        "torch.cuda.is_available()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnttFWhD1fWs",
        "colab_type": "text"
      },
      "source": [
        "Prepare Model Config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvU7OoQ31GX2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size = 15621  # parallel to k=6 in classic k-mers (for this corpus)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lb3LtlN71jrs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "config = BertConfig(\n",
        "    vocab_size=vocab_size,\n",
        "    hidden_size=256,\n",
        "    intermediate_size=1024,\n",
        "    num_hidden_layers=4,\n",
        "    num_attention_heads=4,\n",
        "    max_position_embeddings=512\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rt6S95e1nRe",
        "colab_type": "text"
      },
      "source": [
        "Create BERT model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxfuGnuF1lP5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8e48ec50-d38e-4aa4-8f82-404a98fa758d"
      },
      "source": [
        "model = BertForMaskedLM(config=config)\n",
        "\n",
        "print(f\"BERT model has {model.num_parameters()/10**6}M parameters\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BERT model has 7.437829M parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "314dwNpA1raZ",
        "colab_type": "text"
      },
      "source": [
        "Create Datatset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxoBaUjM1p36",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_path = os.path.join(drive_path, 'vocab.txt')\n",
        "data_path = os.path.join(drive_path, 'SILVA_parsed_V2.tsv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTni8V-U1vF6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "78712cc6-7535-499e-9dbe-9f4b52e82608"
      },
      "source": [
        "dataset = BERT16SDataset(\n",
        "    vocab_path=vocab_path,\n",
        "    data_path=data_path,\n",
        "    block_size=512\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2822: DtypeWarning: Columns (12) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  if self.run_code(code, result):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACTjWIM517rf",
        "colab_type": "text"
      },
      "source": [
        "Crete Data Collator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaL-v1Kz19OV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = BertWordPieceTokenizer(\n",
        "    vocab_path,\n",
        "    handle_chinese_chars=False,\n",
        "    lowercase=False,\n",
        "    unk_token=\"[UNK]\",\n",
        "    sep_token=\"[SEP]\",\n",
        "    pad_token=\"[PAD]\",\n",
        "    cls_token=\"[CLS]\",\n",
        "    mask_token=\"[MASK]\")\n",
        "\n",
        "tokenizer.enable_truncation(512)\n",
        "tokenizer.enable_padding(length=512)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nM-MCvBT1_1i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c6687f51-91de-4573-9195-112ca3b32242"
      },
      "source": [
        "len(tokenizer.get_vocab())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15621"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwB4Qo_X2BGY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_collator = DataCollatorForBertWordPieceTokenizer(\n",
        "    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMu0YWZm2CkZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "93d4309e-4290-4258-cddb-27d9fe7cf105"
      },
      "source": [
        "model(data_collator.collate_batch([dataset[0]])['input_ids'])[0].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 512, 15621])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JbU5Qzv2Ekb",
        "colab_type": "text"
      },
      "source": [
        "Config Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBWwBa08fMlG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model = BertForMaskedLM.from_pretrained(drive_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnOFur9G2Fqj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=os.path.join(drive_path, 'checkpoints'),\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=40,\n",
        "    save_steps=10_000,\n",
        "    logging_steps=500,\n",
        "    save_total_limit=2,\n",
        "    learning_rate=5e-4,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hbVFEty84jg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from typing import Callable, Dict, List, Optional, Tuple\n",
        "import json\n",
        "from transformers.optimization import get_constant_schedule_with_warmup\n",
        "\n",
        "class CustomTrainer(Trainer):\n",
        "\n",
        "    def _log(self, logs: Dict[str, float], iterator: Optional = None) -> None:\n",
        "      if self.epoch is not None:\n",
        "          logs[\"epoch\"] = self.epoch\n",
        "\n",
        "      output = json.dumps({**logs, **{\"step\": self.global_step}})\n",
        "      print(output)\n",
        "  \n",
        "    def get_optimizers(self, num_training_steps: int) -> Tuple[torch.optim.Optimizer, torch.optim.lr_scheduler.LambdaLR]:\n",
        "        optimizer, _ = super(CustomTrainer, self).get_optimizers(num_training_steps)\n",
        "        scheduler = get_constant_schedule_with_warmup(optimizer, num_warmup_steps=self.args.warmup_steps)\n",
        "        return optimizer, scheduler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J559coch2HWo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "cd683cfc-46b8-4de3-80c1-93fed7568b4b"
      },
      "source": [
        "trainer = CustomTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=dataset,\n",
        "    prediction_loss_only=True,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/trainer.py:226: FutureWarning: The `data_collator` should now be a simple callable (function, class with `__call__`), classes with a `collate_batch` are deprecated and won't be supported in a future version.\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RabmaM6Z2KD0",
        "colab_type": "text"
      },
      "source": [
        "Train!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cek_sh9e2Iu5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 779,
          "referenced_widgets": [
            "a9c2a1846e7e43648124311181fb771a",
            "3d17a08352114cbfb0bfb479f2e601c5",
            "e056886b21c44b0798a44c87464f16b2",
            "ad0ba16983b645719ca351a06065e1a0",
            "660d63e998754b43b9c7492ff42f0e06",
            "7139c90a9aa14f67a27c1a0ec3a1d7c8",
            "fcb338f7c24f4c7a8a267386076370d8",
            "44ad9ecd2cea45249cca13ed2956ce18",
            "d5a0e91565af4310bdc670c24cc23b32",
            "febc1871ad444bcca80f08f6bfbcc638",
            "5dd1fc6a76514087901ac891f1c81898",
            "70fd567916ef4c85bdf4ff31451e2c90",
            "62612890d16749bdb745291bab447bdf",
            "6c21a75b5b0847c5a02332e4eb81dc77",
            "4652f026b93f4a33bcfc8e63e6c560c4",
            "5727a783b17b4839be3e9418f268f773"
          ]
        },
        "outputId": "bcd4033d-2484-4b7c-c5a1-ee16febe1a41"
      },
      "source": [
        "%%time\n",
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a9c2a1846e7e43648124311181fb771a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=3.0, style=ProgressStyle(description_width='i…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d5a0e91565af4310bdc670c24cc23b32",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=10801.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "{\"loss\": 2.1806337041854857, \"learning_rate\": 0.0005, \"epoch\": 0.04629200999907416, \"step\": 500}\n",
            "{\"loss\": 2.178268550634384, \"learning_rate\": 0.0005, \"epoch\": 0.09258401999814832, \"step\": 1000}\n",
            "{\"loss\": 2.161776591539383, \"learning_rate\": 0.0005, \"epoch\": 0.13887602999722248, \"step\": 1500}\n",
            "{\"loss\": 2.166535542011261, \"learning_rate\": 0.0005, \"epoch\": 0.18516803999629664, \"step\": 2000}\n",
            "{\"loss\": 2.1483408017158507, \"learning_rate\": 0.0005, \"epoch\": 0.2314600499953708, \"step\": 2500}\n",
            "{\"loss\": 2.1512983677387236, \"learning_rate\": 0.0005, \"epoch\": 0.27775205999444497, \"step\": 3000}\n",
            "{\"loss\": 2.14949022769928, \"learning_rate\": 0.0005, \"epoch\": 0.32404406999351915, \"step\": 3500}\n",
            "{\"loss\": 2.149521510362625, \"learning_rate\": 0.0005, \"epoch\": 0.37033607999259327, \"step\": 4000}\n",
            "{\"loss\": 2.142380564212799, \"learning_rate\": 0.0005, \"epoch\": 0.41662808999166745, \"step\": 4500}\n",
            "{\"loss\": 2.139502103805542, \"learning_rate\": 0.0005, \"epoch\": 0.4629200999907416, \"step\": 5000}\n",
            "{\"loss\": 2.1218170828819276, \"learning_rate\": 0.0005, \"epoch\": 0.5092121099898158, \"step\": 5500}\n",
            "{\"loss\": 2.1171763393878935, \"learning_rate\": 0.0005, \"epoch\": 0.5555041199888899, \"step\": 6000}\n",
            "{\"loss\": 2.1268030951023102, \"learning_rate\": 0.0005, \"epoch\": 0.6017961299879641, \"step\": 6500}\n",
            "{\"loss\": 2.104721169948578, \"learning_rate\": 0.0005, \"epoch\": 0.6480881399870383, \"step\": 7000}\n",
            "{\"loss\": 2.1173931634426117, \"learning_rate\": 0.0005, \"epoch\": 0.6943801499861124, \"step\": 7500}\n",
            "{\"loss\": 2.0971132621765136, \"learning_rate\": 0.0005, \"epoch\": 0.7406721599851865, \"step\": 8000}\n",
            "{\"loss\": 2.105222324132919, \"learning_rate\": 0.0005, \"epoch\": 0.7869641699842607, \"step\": 8500}\n",
            "{\"loss\": 2.088343613862991, \"learning_rate\": 0.0005, \"epoch\": 0.8332561799833349, \"step\": 9000}\n",
            "{\"loss\": 2.1006711251735686, \"learning_rate\": 0.0005, \"epoch\": 0.879548189982409, \"step\": 9500}\n",
            "{\"loss\": 2.10457874417305, \"learning_rate\": 0.0005, \"epoch\": 0.9258401999814831, \"step\": 10000}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-0c647bc3a8b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'trainer.train()'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1187\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'eval'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, model_path)\u001b[0m\n\u001b[1;32m    557\u001b[0m                             \u001b[0mxm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"scheduler.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m                         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_world_master\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 559\u001b[0;31m                             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"optimizer.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    560\u001b[0m                             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"scheduler.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    359\u001b[0m     \u001b[0m_check_dill_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './drive/My Drive/Colab Notebooks/NLP/model/checkpoints/checkpoint-10000/optimizer.pt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRpz7mg6AWQJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainer.save_model(drive_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phMvsFR8z0Zz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "96d976f9-a2ad-4811-ef40-ff93e25dbba5"
      },
      "source": [
        "tokenizer.save_model(drive_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['./drive/My Drive/Colab Notebooks/NLP/model/vocab.txt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpWqFRJmGkI0",
        "colab_type": "text"
      },
      "source": [
        "Extract Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WF7-pMgBdtQv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loaded_model = BertModel.from_pretrained(drive_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqcVNJzqJ6oj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 32\n",
        "dataloader = torch.utils.data.DataLoader(\n",
        "                dataset=dataset,\n",
        "                batch_size=batch_size,\n",
        "                sampler=torch.utils.data.SequentialSampler(dataset),\n",
        "                num_workers=0,\n",
        "                pin_memory=True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlmF-jijKZDi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30HNMuutIzhj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "3cee0d50-55ad-4394-8210-9c05f5d2e657"
      },
      "source": [
        "%%time \n",
        "\n",
        "averaged_embeddings = torch.tensor([], dtype=torch.float)\n",
        "first_batch = True\n",
        "\n",
        "for batch in tqdm(dataloader, position=0, leave=True):\n",
        "    model_outputs = loaded_model.embeddings(batch).mean(dim=1)\n",
        "    if first_batch:\n",
        "      assert batch.shape == torch.Size([batch_size, 512])\n",
        "      assert model_outputs.shape == torch.Size([batch_size, 256])\n",
        "      first_batch = False\n",
        "\n",
        "    averaged_embeddings = torch.cat((averaged_embeddings, model_outputs.detach().cpu()), 0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 13502/13502 [40:43<00:00,  5.53it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 39min 38s, sys: 1min 6s, total: 40min 44s\n",
            "Wall time: 40min 43s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MS8l2qiLe9TL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(averaged_embeddings, os.path.join(drive_path, 'averaged_embeddings'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iKaB-U3mjB8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert averaged_embeddings.shape[0] == len(dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AO5U46kQweO6",
        "colab_type": "text"
      },
      "source": [
        "Extract Weighted Embedding Without Token Padding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1hnOvZDpCzn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "token_weights_df = pd.read_csv(os.path.join(drive_path, 'bpe_token_weights.tsv'), sep='\\t')\n",
        "token_weights = token_weights_df.set_index('token')['weight2'].to_dict()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhY7brD_s63N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unpadded_tokenizer = BertWordPieceTokenizer(\n",
        "    vocab_path,\n",
        "    handle_chinese_chars=False,\n",
        "    lowercase=False,\n",
        "    unk_token=\"[UNK]\",\n",
        "    sep_token=\"[SEP]\",\n",
        "    pad_token=\"[PAD]\",\n",
        "    cls_token=\"[CLS]\",\n",
        "    mask_token=\"[MASK]\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L656rs0oFyP3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "40821fac-0d86-44e1-e054-56ca5e89065d"
      },
      "source": [
        "averaged_embeddings = torch.tensor([], dtype=torch.float)\n",
        "\n",
        "for sample in tqdm(dataset.samples[:50000], position=0, leave=True):\n",
        "\n",
        "  sample_splitted = dataset._split_sequence_by_max_word_length(sample)\n",
        "  tokens = dataset.tokenizer.encode(sample_splitted)\n",
        "  embedding = loaded_model.embeddings(torch.tensor(tokens.ids, dtype=torch.long).expand(1, -1))\n",
        "\n",
        "  tokens_unpadded = unpadded_tokenizer.encode(sample_splitted, add_special_tokens=False)\n",
        "  original_len = len(tokens_unpadded.ids)\n",
        "\n",
        "  weights = np.array([token_weights[k] for k in tokens_unpadded.tokens])\n",
        "  weights_normalized = weights# / np.sum(weights)\n",
        "  weights_tensor = torch.tensor([w * np.ones([256]) for w in weights_normalized]).view(1, -1, 256)\n",
        "\n",
        "  averaged_embedding = torch.mul(embedding[:, 1:original_len + 1, :], weights_tensor).mean(dim=1)\n",
        "  averaged_embeddings = torch.cat((averaged_embeddings, averaged_embedding.detach().cpu()), 0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 50000/50000 [21:04<00:00, 39.54it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYE5cLPSsrMl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(averaged_embeddings, os.path.join(drive_path, 'averaged_embeddings_no_padding__weight2'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQnbGsjbtdLp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "f925f297-c501-4ebf-f871-6771c1dc7dc4"
      },
      "source": [
        "assert averaged_embeddings.shape[0] == len(dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-49f493d93f7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0maveraged_embeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ]
    }
  ]
}